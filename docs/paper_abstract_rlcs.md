# Abstract

Deep learning models deployed in open-world environments frequently encounter out-of-distribution (OOD) inputs that violate their training assumptions, leading to silent failures and overconfident predictions. Existing mitigation strategies, such as post-hoc calibration or Bayesian uncertainty estimation, often incur prohibitive computational costs or require extensive model retraining. We introduce **Representation-Level Control Surfaces (RLCS)**, a systems paradigm that embeds lightweight, deterministic reliability sensing directly into the latent feature space of learned models. An RLCS system intercepts feature representations, evaluates their consistency against a reference manifold, and emits formal control signals without executing decisions itself. We present **ResLik** (Residual Likelihood Sensor), a concrete instantiation of the RLCS sensing layer that computes a likelihood-gated residual discrepancy metric. By strictly separating reliability sensing from execution policy, RLCS enables the construction of "self-aware" data pipelines in robotics, applied AI, and scientific computing that can gracefully degrade or defer execution when representation assumptions fail, with negligible runtime overhead.
